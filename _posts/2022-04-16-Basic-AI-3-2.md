---
title:  "인공기능의 기초 3-2 지역 탐색"
layout: single
date: 2022-04-16T11:00:00+09:00
last_modified_at: 2022-04-16
category: Basic-AI
use_math: true
---
  
## Local Search Algorithm
Local Search는 딥러닝에서도 적극적으로 활용하는 방법이다. 많은 경우에 목적까지의 path보다 목적에 도달하는 거 자체가 중요한 경우가 매우 많다. 저번 글에서 살펴본 도시 이동 문제에서는 최단 거리로 도달하는 것이 물론 가장 좋겠지만 체스 게임을 탐색 문제로 정의해본다면 최단수도 좋겠지만 결국 이기는 것이 목적이 될 것이다. 이럴 때 지역 탐색을 많이 활용한다고 한다.  
  
기본 아이디어는 이와 같다. 문제를 풀 때 global한 reasoning을 통해서 문제를 해결하겠다는 것이 아닌, 매 state마다 지금보다 나은 state로만 가보자는 식으로 하나하나 가는 것이다. 이렇게 함으로써 메모리를 매우 적게 사용한다는 장점과 search space가 큰 문제에서 글로벌하게 분석을 하기 위해서는 정말 많은 시간 계산이 필요한데 그런 거 없이도 꽤 괜찮은 solution을 얻을 수 있다는 장점이 있다.  
  
  
### Solving n-queens with Hill-Climbing Search 
![nqeen](/assets/img/2022-04-16-Basic-AI-3-2/1.png){: .center}  

$n \times n$ 보드에서 $n$개의 queen을 서로 공격하지 못하게 올려두는 방법을 찾는 문제이다. 빠르게 찾는 것도 좋지만 이런 배열을 찾는 것 자체가 목적이라고 할 수 있다. 이 경우에 local search를 이용해서 해를 구할 수 있다. 그 중 하나인 Hill-Climbing Search를 살펴보자.  
  
  
Hill-Climbing Search의 비유를 살펴보면 *짙은 안개* 속에서 *기억상실증*을 갖고 에베레스트를 올라가는 것과 같다.  
이는 local하게만 볼 수 있는 상황, 내가 기존에 이 위치를 왔는지는 모르고 내 state에서 주변 state로 이동하는 것만 반복하는 것을 의미한다. 그냥 주변에 더 *급하게 높은 곳*으로 한발 한발 올라가는 것이다. local search의 기본 철학중 하나가 메모리를 최대한 적게 활용하는 것이기 때문에 지금까지 온 path도 기억하지 않는다.  
  
매우 간단한 개념을 가지고 있지만 치명적인 단점을 가지고 있는데 local maxima에 빠질 수 있다는 문제점이다. 이는 지역적으로 최댓값을 가지는 영역이다. global maximum(최적의 솔루션)은 따로 있는데 지역적으로 최댓값을 가지는 곳에 갇혀버리는(get stuck in local maxima) 것이다. 그래서 Hill-Climbing Search는 initial point(시작점)가 어디냐에 따라서 다른 결과를 가질 수 있다.  
  
![8queen](/assets/img/2022-04-16-Basic-AI-3-2/2.png){: .center}  
  
이는 8-queens 문제이고 $h$는 서로 공격할 수 있는 쌍을 의미한다고 하자. 그럼 $h$가 0이 되는 상태가 최적해 global minimum이 될 것이다.  
여기서 기본 아이디어는 8개의 말 중 하나를 움직였을 때 h 값이 가장 많이 떨어지는 말을 찾는 것이다.  
  
![8queen](/assets/img/2022-04-16-Basic-AI-3-2/3.png){: .center}  
  
위 초기 상태에서 이를 계속 반복하면 $h = 1$에 도달하게 되고 더 이상 h를 줄일 수 있는 배열은 존재하지 않게 된다. 따라서 아주 간단하다는 장점과 최적의 솔루션($h = 0$)에 도달하지 못한다는 단점을 볼 수 있다.   

### Simulated Annealing Search
이런 문제를 해결하기 위해서 나온 local search 중 하나가 Simulated Annealing Search이다. Annealing은 금속의 강도를 높이기 위해 담금질 한다는 뜻을 담고 있다. Hill-Climbing Search에서는 움직일 수 있는 action 중에서 가장 objective를 최대화하는 방향으로만 움직였다면, Simulated Annealing Search에서는 현재 상태보다 안 좋은 move를 허락을 하는데, 초반에는 그 빈도를 크게 주고 갈수록 이를 줄이는 방식이다. local maxima를 피하기 위해 random walk로 무작위성을 추가해 내려가기도 한다는 것이다.  
  
따라서 random move를 선택을 하게 되는데, 선택했을 때 현재 상황보다 좋아진다면 항상 이를 받아들이고 좋아지지 않는다면 randomness를 통해서 받아들이든지 안 받아들이든지를 결정한다.  
  
담금질이라는 것이 기본 아이디어이기 때문에 온도 T라는 개념이 등장하는데 온도가 높으면 더 유연한 randomness가 더 많은 것을 의미하고 가면 갈수록 온도가 식어가면서 randomness가 더 줄어들게 된다.  
  
  
![sas](/assets/img/2022-04-16-Basic-AI-3-2/4.png){: .center}  
  
위는 Simulated Annealing Search의 pseudo code이다.  
반복을 계속 돌면서 shedule이라는 함수에 iteration을 넘겨주고 온도 T를 받아온다. 따라서 shedule 함수는 반복(iteration)마다 온도를 어떻게 줄여나갈지에 대한 함수이다.  
  
온도가 0이 되면 현재 상태를 return 하고, 온도가 0이 아니라면 다음 random한 move를 선택한다.  
선택한 move가 더 좋은 move인지 판단하기 위해서 $\Delta E$를 사용하는데, **선택한 move - 현재**의 값이다.  
따라서 이가 양수(> 0)라면 current <- next 받아 들이고, 아니라면 확률 분포 값을 사용해 받아들일지 말지 결정한다.  
$e^\frac{\Delta E}{T}$를 보면 $\Delta E$는 항상 음수이기 때문에 이의 절댓값이 클 때(현재 상황보다 많이 안 좋아질 때), 온도(T)가 낮을 때 이 변화를 받아들일 확률이 더욱 적어지게 된다.  
  
이 외에도 다양한 local search가 있으니 궁금하면 찾아보도록 하자.  
  

**KMOOC에서 김건희 교수님의 인공기능의 기초 강의를 보실 수 있습니다.**